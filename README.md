<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="description" content="Chainâ€‘ofâ€‘Thought wrapper and GUI for Hugging Face causal LMs with stepâ€‘byâ€‘step reasoning and telemetry.">
</head>
<body>

  <h1>ğŸš€ NeuroReasoner Chainâ€‘ofâ€‘Thought Toolkit</h1>

  <p>
    A breakthrough openâ€‘source suite providing:
    <strong>alwaysâ€‘on</strong> Chainâ€‘ofâ€‘Thought reasoning,
    <strong>selfâ€‘consistency</strong> sampling, and
    <strong>realâ€‘time telemetry</strong>,
    all packaged as a Python wrapper and a futuristic Streamlit GUI.
  </p>

  <h2>ğŸ“‚ Included Scripts</h2>
  <ul>
    <li><code>chain_of_thought_wrapper.py</code> â€“ the core Python module you import into your own scripts.</li>
    <li><code>chain_of_thought_gui.py</code> â€“ a Streamlit app for interactive, noâ€‘code usage.</li>
  </ul>

  <h2>âš™ï¸ Installation</h2>
  <ol>
    <li>Clone or unzip this folder.</li>
    <li>Install required packages:
      <pre><code>pip install torch transformers streamlit pynvml</code></pre>
    </li>
    <li>Ensure your model checkpoint (e.g. <code>ayjays132/NeuroReasonerâ€‘1â€‘NRâ€‘1</code>) is accessible
      or change the name in the GUI script.
    </li>
  </ol>

  <h2>ğŸ‘©â€ğŸ’» Importing &amp; Using the Wrapper</h2>
  <p>Embed stepâ€‘byâ€‘step reasoning directly in your Python code:</p>
  <pre><code>from chain_of_thought_wrapper import ChainOfThoughtWrapper
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# 1) Load your tokenizer & model
tokenizer = AutoTokenizer.from_pretrained("ayjays132/NeuroReasoner-1-NR-1")
model     = AutoModelForCausalLM.from_pretrained("ayjays132/NeuroReasoner-1-NR-1")
device    = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

# 2) Wrap with CoT logic
cot = ChainOfThoughtWrapper(model=model, tokenizer=tokenizer, device=device)

# 3) Prepare your prompt
inputs = tokenizer("Why is the sky blue?", return_tensors="pt").to(device)

# 4) Generate stepâ€‘byâ€‘step reasoning
result = cot.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask)

# 5) Inspect the output
for i, step in enumerate(result["reasoning_steps"][0], 1):
    print(f"Step {i}:", step)
print("Final Answer:", result["final_answers"][0])
</code></pre>

  <h2>ğŸ–¥ï¸ Launching the GUI</h2>
  <p>No code edits neededâ€”just run:</p>
  <pre><code>streamlit run chain_of_thought_gui.py</code></pre>
  <p>Then open the local URL in your browser. Adjust model name, device, number of chains, sampling parameters, and enter your prompt.</p>

  <h2>ğŸ”§ GUI Configuration Options</h2>
  <ul>
    <li><strong>Model</strong>: Hugging Face repo or local path.</li>
    <li><strong>Device</strong>: cuda or cpu.</li>
    <li><strong># Chains</strong>: Number of reasoning samples.</li>
    <li><strong>Selfâ€‘Consistency</strong>: Toggle majorityâ€‘vote across chains.</li>
    <li><strong>Max New Tokens</strong>: Length of generated reasoning.</li>
    <li><strong>Temperature</strong>, <strong>Topâ€‘k</strong>, <strong>Topâ€‘p</strong> &amp; <strong>Noâ€‘repeat nâ€‘gram</strong>: Sampling controls.</li>
  </ul>

  <h2>â³ Example GUI Session</h2>
  <pre><code>â–¶ Prompt: What causes rainbows?
â–¶ Chains: 3, Selfâ€‘Consistency: on
â–¶ Sampling: temp 0.7, topâ€‘k 50, topâ€‘p 0.9
â€¦generatingâ€¦
â–¼ Chain 1 â–¼
1. Sunlight is composed of multiple colors.
2. Water droplets refract and disperse each color.
3. Observer sees spectrum as arc.
Final Answer: Rainbows form when sunlight refracts and disperses through droplets, separating into colors.
â€¦</code></pre>

  <h2>ğŸ“œ License</h2>
  <p>Released under the <strong>MIT License</strong>. Free to use, modify, and shareâ€”empower everyone with transparent, stepâ€‘byâ€‘step AI reasoning!</p>

</body>
</html>
